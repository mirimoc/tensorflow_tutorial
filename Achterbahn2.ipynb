{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programme\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erklärung des Beispiels\n",
    "Wir wollen unser erstes Beispiel programmieren und da wir die ganze Zeit von einer Achterbahn geredet haben, werden wir diese jetzt in TensorFlow realisieren. Zugegeben eine äußerst stark vereinfachte Variante, aber für das Verständnis vollkommen ausreichend!\n",
    "\n",
    "Wie im oberen Teil beschrieben, unterteilt sich die Arbeit mit TensorFlow in zwei Phasen:\n",
    " 1. Erstellung des Graphen: In unserem Falle wäre das die Konstruktion unserer Achterbahn\n",
    " 2. Ausführung des Graphen: in dieser Phase lassen wir unsere Insassen einfach los und schauen mal was passiert\n",
    " \n",
    "Um die Zahlen zu verstehen, möchte ich euch zudem erklären, was überhaupt das Ziel unseres Modells ist. Wir haben 8 Probanden mit verschiedenen Angstzuständen. Je größer dieser Wert ist, desto ängstlicher sind unsere Probanden. Unser Ziel ist es alle Probanden, welche einen Angstzustand >5 haben, nach der Fahrt unserer Achterbahn den Wunsch verspüren nie mitgefahren zu sein! Die Größe die wir dabei optimieren wollen, ist die Geschwindigkeit. Wenn die Geschwindigkeit zu schnell ist, dann fürchten sich zu viele, wenn wir zu langsam fahren, dann fürchtet sich womöglich niemand. \n",
    "\n",
    "__Wir suchen also die passende Geschwindigkeit um unser Ziel Angstzustand > 5 => Wunsch nie mitgefahren zu sein.__\n",
    "\n",
    "Unser Szenario ist also eine Klassifikationsaufgabe!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eingangssignale: Zustände der Gäste \n",
    "Wir sehen hier zwei Vektoren bzw. Tensoren die Informationen über unsere Gäste haben. \n",
    " * `x_input` ist der Angstzustand unserer Gäste\n",
    " * `y_input` ist unser gewünschtes Ausgangsssignal: 0 $\\rightarrow$ normal, 1 $\\rightarrow$ Wunsch nicht mitgefahren zu sein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eingangssignale, Tensor\n",
    "# Zustand der Gäste -> je  größer die Zahl desto größer der Angstzustand der Gäste\n",
    "x_input = [[-10], # <- Angstzustand Gast 1\n",
    "           [-5],  # <- Angstzustand Gast 2\n",
    "           [-2],  # <- Angstzustand Gast 3\n",
    "           [-1],\n",
    "           [2],\n",
    "           [1],\n",
    "           [5],\n",
    "           [9]]   # <- Angstzustand Gast 8\n",
    "\n",
    "# gewünschtes Ausgangssignal, Tensor\n",
    "# Endzustand der Gäste -> Wunsch die Bahn nie gefahren zu sein\n",
    "y_input = [[0], \n",
    "           [0],\n",
    "           [0],\n",
    "           [0],\n",
    "           [0],\n",
    "           [0],\n",
    "           [1], # <- bereut die Fahrt\n",
    "           [1]] # <- bereut die Fahrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellung unseres Graphen: Konstruktion der Achterbahn\n",
    "Nun konstruieren wir unsere Achterbahn des Grauens: \n",
    "\n",
    "Eine undichte Gleichrichter-Aktivierungsfunktion (engl. leaky rectifier) mit einer Matrizenmultiplikation aus einem Vektor und einem Skalar mit anschließender Fehleroptimierung der ... MUHAHAHAHAHAHA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platzhalter\n",
    "    # Wagon, Eingangsgröße\n",
    "wagon = tf.placeholder(tf.float32, shape = [8, 1])\n",
    "    # gewünschter Endzustand der Gäste\n",
    "ziel = tf.placeholder(tf.float32, shape = [8, 1]) \n",
    "y_true = ziel\n",
    "# Variable \n",
    "    # Geschwindigkeit des Wagons\n",
    "geschw = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "\n",
    "# Knoten mit Matrizenoperator, Fahrelement, z.B. Airtime-Hügel\n",
    "z = tf.matmul(wagon, geschw)\n",
    "\n",
    "y_pred = tf.nn.leaky_relu(z)\n",
    "# Fehlerfunktion\n",
    "err = tf.reduce_mean(tf.pow(y_true - y_pred,2))\n",
    "# Optimierer\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=0.005).minimize(err)\n",
    "# Initialisierung der Variablen (Geschwindigkeit)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf den ersten Blick vielleicht ein wenig verwirrend, deshalb wollen wir alles Schritt für Schritt durchgehen:\n",
    "\n",
    " * `wagon` ist unser Wagon, welcher die Achterbahn auf und ab fährt. Gefühlt mit unseren Probanden. Da diese Größen aus unseren externen Daten ausgezogen werden, liegt diese Größe als Platzhalter vor.\n",
    "     - Wichtig bei __[Platzhalter](https://www.tensorflow.org/api_docs/python/tf/placeholder)__ ist, dass ihr den Datentyp angeben müsst!\n",
    "     - Optional könnt ihr auch die Form angeben. Bei einem so überschaubaren Beispiel machen wir das auch.\n",
    " * `ziel, y_true` ist der Endzustand unserer Gäste, den wir uns für die Probanden erhoffen, d.h. es ist unser `y_input`. Auch hier kommen die Daten von außerhalb und daher wird der Platzhalter genutzt.\n",
    " * `v` ist unsere Geschwindigkeit und da diese optimiert werden muss, liegt sie als Variable vor\n",
    "     - Wie ihr seht ist in der __[Variable](https://www.tensorflow.org/api_docs/python/tf/Variable)__ noch eine weitere __[Funktion](https://www.tensorflow.org/api_docs/python/tf/random_normal)__, welche uns eine zufällige Zahl ausgibt (ihr könnt auch eine Zahl eingeben, aber wir sind faul und lassen daher den Zufall entscheiden)\n",
    "\n",
    "Nun zum zweiten Teil der Modellierung in dem wir ein klein wenig Mathematik benötigen. Schauen wir uns folgende Gleichung an:\n",
    "\n",
    "* `tf.matmul(wagon, v)`: ist unsere Matrizenmultiplikation -> Da unsere Größen in Vektoren/Tensoren vorliegen, können wir diese nicht einfach multiplizieren, wie z.B. 2*2 = 4. Bei der Multiplikation von Matrizen oder Vektoren müssen bestimmte Bedingungen herrschen, damit diese überhaupt multipliziert werden können. Für ausführlichere Erklärungen, schreibt es einfach in die Kommentare.\n",
    "* `tf.nn.leaky_relu(z)`: Für all diejenigen, die sich bereits mit neuronalen Netzen beschäftigt haben; leaky_relu ist in unserem Fall die Aktivierungsfunktion. Für alle anderen, die mit der Aktivierungsfunktion noch nichts anfangen können: Die Kombination (Matrizenmultiplikation) aus dem Angstzustand und der Geschwindigkeit erreicht den Wert $Z$. Je nachdem welche Aktivierungsfunktion haben triggert dieser Wert $Z$ unsere Emotionen, so dass wir den Wunsch verspüren, die Bahn nie gefahren zu haben. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
